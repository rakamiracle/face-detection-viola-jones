"""
=================================================================
PROYEK PENGENALAN POLA - DETEKSI WAJAH VIOLA-JONES
UNTUK LAPORAN MATA KULIAH (100 DATA)
=================================================================

FITUR LENGKAP:
‚úÖ Minimum 100 Data untuk Testing
‚úÖ 12 Feature Extraction (Haar, Histogram, Edge, Texture, Intensity)
‚úÖ Classification (Viola-Jones Cascade Classifier)
‚úÖ 3 Skenario Testing (70:30, 80:20, 90:10)
‚úÖ Evaluation Metrics (Accuracy, Precision, Recall, F1-Score)
‚úÖ Confusion Matrix (TP, FP, TN, FN)
‚úÖ Export CSV (Hasil + Fitur per gambar)
‚úÖ Grafik Perbandingan Akurasi

INSTALL:
pip install flask opencv-python pillow numpy pandas openpyxl matplotlib

JALANKAN:
python3 app.py
=================================================================
"""

from flask import Flask, render_template, request, jsonify, send_file
import cv2
import numpy as np
from PIL import Image
import base64
import io
import os
import time
from datetime import datetime
import sqlite3
import json
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# INISIALISASI
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB

# BUAT FOLDER
for folder in ['uploads', 'results', 'database', 'batch_test', 'exports', 'charts']:
    if not os.path.exists(folder):
        os.makedirs(folder)

# LOAD MODEL VIOLA-JONES
print("üîÑ Loading Viola-Jones Cascade Classifiers...")
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
print("‚úÖ Models loaded!")

# DATABASE
def init_db():
    conn = sqlite3.connect('database/faces.db')
    c = conn.cursor()
    
    c.execute('''CREATE TABLE IF NOT EXISTS detections
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  timestamp TEXT,
                  face_count INTEGER,
                  eye_count INTEGER,
                  smile_count INTEGER,
                  process_time INTEGER,
                  image_path TEXT,
                  features TEXT)''')
    
    c.execute('''CREATE TABLE IF NOT EXISTS batch_results
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  batch_name TEXT,
                  timestamp TEXT,
                  split_ratio TEXT,
                  total_images INTEGER,
                  true_positive INTEGER,
                  false_positive INTEGER,
                  true_negative INTEGER,
                  false_negative INTEGER,
                  accuracy REAL,
                  precision_val REAL,
                  recall_val REAL,
                  f1_score REAL)''')
    
    c.execute('''CREATE TABLE IF NOT EXISTS feature_table
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  batch_name TEXT,
                  image_no INTEGER,
                  filename TEXT,
                  label INTEGER,
                  integral_mean REAL,
                  integral_std REAL,
                  hist_mean REAL,
                  hist_std REAL,
                  hist_skew REAL,
                  edge_density REAL,
                  texture_var REAL,
                  mean_intensity REAL,
                  std_intensity REAL,
                  min_intensity REAL,
                  max_intensity REAL,
                  face_detected INTEGER)''')
    
    conn.commit()
    conn.close()

init_db()


# ============================================================
# EKSTRAKSI 12 FITUR
# ============================================================
def ekstraksi_fitur_lengkap(image):
    """
    Ekstraksi 12 fitur seperti laporan referensi (MFCC ‚Üí Fitur Image)
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    features = {}
    
    # 1-2. INTEGRAL IMAGE FEATURES (mirip Haar-like)
    integral = cv2.integral(gray)
    features['integral_mean'] = float(np.mean(integral))
    features['integral_std'] = float(np.std(integral))
    
    # 3-5. HISTOGRAM FEATURES
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    features['hist_mean'] = float(np.mean(hist))
    features['hist_std'] = float(np.std(hist))
    features['hist_skew'] = float(np.mean((hist - np.mean(hist))**3))
    
    # 6. EDGE FEATURES
    edges = cv2.Canny(gray, 100, 200)
    features['edge_density'] = float(np.sum(edges > 0) / edges.size)
    
    # 7. TEXTURE FEATURES
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    features['texture_var'] = float(laplacian.var())
    
    # 8-11. INTENSITY FEATURES
    features['mean_intensity'] = float(np.mean(gray))
    features['std_intensity'] = float(np.std(gray))
    features['min_intensity'] = float(np.min(gray))
    features['max_intensity'] = float(np.max(gray))
    
    return features


# ============================================================
# DETEKSI WAJAH + EKSTRAKSI FITUR
# ============================================================
def deteksi_wajah_lengkap(image, detect_smile=True):
    """
    Deteksi wajah dengan Cascade Classifier + ekstraksi fitur
    """
    start = time.time()
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # DETEKSI WAJAH (CASCADE CLASSIFIER - MULTI-STAGE)
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(30, 30),
        flags=cv2.CASCADE_SCALE_IMAGE
    )
    
    total_eyes = 0
    total_smiles = 0
    face_details = []
    
    for idx, (x, y, w, h) in enumerate(faces, 1):
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = image[y:y+h, x:x+w]
        
        # Ekstraksi fitur per wajah
        face_roi = image[y:y+h, x:x+w]
        face_features = ekstraksi_fitur_lengkap(face_roi)
        
        # Deteksi mata
        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 10, minSize=(20, 20))
        num_eyes = len(eyes)
        total_eyes += num_eyes
        
        # Deteksi senyum
        has_smile = False
        if detect_smile:
            roi_mouth = roi_gray[h//2:, :]
            smiles = smile_cascade.detectMultiScale(roi_mouth, 1.8, 20, minSize=(25, 25))
            if len(smiles) > 0:
                has_smile = True
                total_smiles += 1
        
        # Confidence
        confidence = min(num_eyes * 50, 100)
        
        # Gambar deteksi
        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)
        cv2.putText(image, f'Face #{idx}', (x, y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255, 0, 0), 2)
        
        if has_smile:
            cv2.putText(roi_color, 'SMILE', (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        cv2.putText(image, f"Eyes: {num_eyes}", (x+w+10, y+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(image, f"Conf: {confidence}%", (x+w+10, y+40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        face_details.append({
            'id': int(idx),
            'position': {'x': int(x), 'y': int(y), 'w': int(w), 'h': int(h)},
            'eyes': int(num_eyes),
            'smile': bool(has_smile),
            'confidence': int(confidence),
            'features': face_features
        })
    
    process_time = int((time.time() - start) * 1000)
    
    # Summary overlay
    cv2.rectangle(image, (10, 10), (300, 100), (0, 0, 0), -1)
    cv2.putText(image, f"Faces: {len(faces)}", (20, 35), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.putText(image, f"Eyes: {total_eyes}", (20, 60), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
    cv2.putText(image, f"Smiles: {total_smiles}", (20, 85), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
    
    # Ekstraksi fitur global
    global_features = ekstraksi_fitur_lengkap(image)
    
    return {
        'image': image,
        'face_count': len(faces),
        'eye_count': total_eyes,
        'smile_count': total_smiles,
        'process_time': process_time,
        'details': face_details,
        'global_features': global_features
    }


# ============================================================
# HITUNG METRIK EVALUASI
# ============================================================
def hitung_metrik(tp, fp, tn, fn):
    """
    Hitung Accuracy, Precision, Recall, F1-Score
    """
    total = tp + tn + fp + fn
    
    accuracy = (tp + tn) / total if total > 0 else 0
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'accuracy': round(accuracy * 100, 2),
        'precision': round(precision * 100, 2),
        'recall': round(recall * 100, 2),
        'f1_score': round(f1 * 100, 2),
        'sensitivity': round(recall * 100, 2),  # Sensitivity = Recall
        'specificity': round((tn / (tn + fp) if (tn + fp) > 0 else 0) * 100, 2)
    }


# ============================================================
# BATCH TEST DENGAN SPLIT RATIO (100 DATA)
# ============================================================
def batch_test_with_split(images_data, ground_truth, split_ratio='70:30'):
    """
    Test dengan pembagian data (simulasi train:test)
    Karena pakai pre-trained model, ini hanya simulasi pembagian data uji
    """
    # Split data
    total = len(images_data)
    if split_ratio == '70:30':
        test_count = int(total * 0.3)
    elif split_ratio == '80:20':
        test_count = int(total * 0.2)
    elif split_ratio == '90:10':
        test_count = int(total * 0.1)
    else:
        test_count = int(total * 0.3)
    
    # Random sample untuk test
    import random
    test_indices = random.sample(range(total), test_count)
    
    results = []
    tp = fp = tn = fn = 0
    feature_data = []
    
    for idx in test_indices:
        image, filename = images_data[idx]
        expected = ground_truth[idx]
        
        result = deteksi_wajah_lengkap(image.copy(), detect_smile=False)
        detected = result['face_count']
        
        # Klasifikasi
        if expected > 0 and detected > 0:
            tp += 1
            classification = 'TP'
        elif expected == 0 and detected == 0:
            tn += 1
            classification = 'TN'
        elif expected == 0 and detected > 0:
            fp += 1
            classification = 'FP'
        else:
            fn += 1
            classification = 'FN'
        
        results.append({
            'no': len(results) + 1,
            'filename': filename,
            'kelas_asli': 'Ada Wajah' if expected > 0 else 'Tidak Ada',
            'hasil_klasifikasi': 'Ada Wajah' if detected > 0 else 'Tidak Ada',
            'expected_count': expected,
            'detected_count': detected,
            'classification': classification,
            'status': 'Benar' if classification in ['TP', 'TN'] else 'Salah',
            'process_time': result['process_time']
        })
        
        # Simpan fitur untuk tabel (SEPERTI TABEL MFCC DI LAPORAN)
        features = result['global_features']
        features['no'] = len(results)
        features['filename'] = filename
        features['label'] = expected
        features['face_detected'] = detected
        feature_data.append(features)
    
    metrics = hitung_metrik(tp, fp, tn, fn)
    
    return {
        'results': results,
        'features': feature_data,
        'confusion_matrix': {'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn},
        'metrics': metrics,
        'split_ratio': split_ratio,
        'total_images': len(test_indices)
    }


# ============================================================
# BUAT GRAFIK PERBANDINGAN (SEPERTI LAPORAN)
# ============================================================
def create_comparison_chart(batch_results):
    """
    Buat grafik batang seperti di laporan referensi
    """
    try:
        scenarios = []
        accuracies = []
        sensitivities = []
        specificities = []
        
        for result in batch_results:
            scenarios.append(result['split_ratio'])
            accuracies.append(result['accuracy'])
            sensitivities.append(result['sensitivity'])
            specificities.append(result['specificity'])
        
        # Create chart
        x = np.arange(len(scenarios))
        width = 0.25
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.bar(x - width, accuracies, width, label='Akurasi', color='#4CAF50')
        ax.bar(x, sensitivities, width, label='Sensitivitas', color='#2196F3')
        ax.bar(x + width, specificities, width, label='Spesifisitas', color='#FF9800')
        
        ax.set_xlabel('Skenario Pembagian Data (Latih:Uji)', fontweight='bold', fontsize=12)
        ax.set_ylabel('Nilai (%)', fontweight='bold', fontsize=12)
        ax.set_title('Grafik Perbandingan Metrik Evaluasi', fontweight='bold', fontsize=14)
        ax.set_xticks(x)
        ax.set_xticklabels(scenarios)
        ax.legend(loc='lower right')
        ax.grid(axis='y', alpha=0.3)
        ax.set_ylim([0, 100])
        
        # Add value labels on bars
        for i, v in enumerate(accuracies):
            ax.text(i - width, v + 2, f'{v}%', ha='center', fontsize=9, fontweight='bold')
        for i, v in enumerate(sensitivities):
            ax.text(i, v + 2, f'{v}%', ha='center', fontsize=9, fontweight='bold')
        for i, v in enumerate(specificities):
            ax.text(i + width, v + 2, f'{v}%', ha='center', fontsize=9, fontweight='bold')
        
        # Save chart
        chart_path = f"charts/comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.tight_layout()
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return chart_path
        
    except Exception as e:
        print(f"Error creating chart: {str(e)}")
        return None


# ============================================================
# ROUTES
# ============================================================
@app.route('/')
def home():
    return render_template('index.html')


@app.route('/detect', methods=['POST'])
def detect():
    try:
        data = request.json
        image_b64 = data['image'].split(',')[1]
        image_bytes = base64.b64decode(image_b64)
        
        pil_image = Image.open(io.BytesIO(image_bytes))
        image_array = np.array(pil_image)
        
        if len(image_array.shape) == 3:
            image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
        
        # DETEKSI & KLASIFIKASI
        result = deteksi_wajah_lengkap(image_array, detect_smile=data.get('detect_smile', True))
        
        # Simpan
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_path = f"results/result_{timestamp}.jpg"
        cv2.imwrite(result_path, result['image'])
        
        # Database
        conn = sqlite3.connect('database/faces.db')
        c = conn.cursor()
        c.execute('''INSERT INTO detections 
                     (timestamp, face_count, eye_count, smile_count, process_time, image_path, features)
                     VALUES (?, ?, ?, ?, ?, ?, ?)''',
                  (datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                   result['face_count'], result['eye_count'], result['smile_count'],
                   result['process_time'], result_path, json.dumps(result['global_features'])))
        conn.commit()
        conn.close()
        
        # Encode hasil
        _, buffer = cv2.imencode('.jpg', result['image'])
        result_b64 = base64.b64encode(buffer).decode('utf-8')
        
        return jsonify({
            'success': True,
            'image': result_b64,
            'face_count': result['face_count'],
            'eye_count': result['eye_count'],
            'smile_count': result['smile_count'],
            'process_time': result['process_time'],
            'resolution': f"{image_array.shape[1]} x {image_array.shape[0]}",
            'details': result['details'],
            'features': result['global_features'],
            'saved_path': result_path
        })
        
    except Exception as e:
        print(f"Error: {str(e)}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/batch_upload', methods=['POST'])
def batch_upload():
    """Upload batch MINIMUM 100 DATA dengan 3 skenario testing"""
    try:
        files = request.files.getlist('images')
        ground_truth = request.form.getlist('ground_truth')
        
        if not files or len(files) < 100:
            return jsonify({'success': False, 'message': f'Minimum 100 gambar diperlukan! Anda upload {len(files)} gambar.'}), 400
        
        print(f"üìä Processing {len(files)} images...")
        
        # Load images
        images_data = []
        for file in files:
            image_bytes = file.read()
            pil_image = Image.open(io.BytesIO(image_bytes))
            image_array = np.array(pil_image)
            
            if len(image_array.shape) == 3:
                image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            
            images_data.append((image_array, file.filename))
        
        # Ground truth
        if not ground_truth or len(ground_truth) != len(files):
            ground_truth = [1] * len(files)
        else:
            ground_truth = [int(x) for x in ground_truth]
        
        # TEST 3 SKENARIO
        batch_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        all_results = []
        
        for split_ratio in ['70:30', '80:20', '90:10']:
            print(f"üîÑ Testing {split_ratio}...")
            batch_result = batch_test_with_split(images_data, ground_truth, split_ratio)
            
            # Simpan ke database
            conn = sqlite3.connect('database/faces.db')
            c = conn.cursor()
            c.execute('''INSERT INTO batch_results 
                         (batch_name, timestamp, split_ratio, total_images, 
                          true_positive, false_positive, true_negative, false_negative, 
                          accuracy, precision_val, recall_val, f1_score)
                         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                      (f"{batch_name}_{split_ratio}", 
                       datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                       split_ratio,
                       batch_result['total_images'],
                       batch_result['confusion_matrix']['TP'],
                       batch_result['confusion_matrix']['FP'],
                       batch_result['confusion_matrix']['TN'],
                       batch_result['confusion_matrix']['FN'],
                       batch_result['metrics']['accuracy'],
                       batch_result['metrics']['precision'],
                       batch_result['metrics']['recall'],
                       batch_result['metrics']['f1_score']))
            
            # Simpan fitur ke tabel (TABEL SEPERTI HASIL EKSTRAKSI FITUR AUDIO DI LAPORAN)
            for feat in batch_result['features']:
                c.execute('''INSERT INTO feature_table 
                             (batch_name, image_no, filename, label, integral_mean, integral_std, 
                              hist_mean, hist_std, hist_skew, edge_density, texture_var, 
                              mean_intensity, std_intensity, min_intensity, max_intensity, face_detected)
                             VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                          (f"{batch_name}_{split_ratio}", feat['no'], feat['filename'], feat['label'],
                           feat['integral_mean'], feat['integral_std'],
                           feat['hist_mean'], feat['hist_std'], feat['hist_skew'],
                           feat['edge_density'], feat['texture_var'],
                           feat['mean_intensity'], feat['std_intensity'],
                           feat['min_intensity'], feat['max_intensity'], feat['face_detected']))
            
            conn.commit()
            conn.close()
            
            # Export CSV hasil (SEPERTI TABEL 3.4, 3.5, 3.6 DI LAPORAN)
            df_results = pd.DataFrame(batch_result['results'])
            csv_results_path = f"exports/{batch_name}_{split_ratio}_hasil_klasifikasi.csv"
            df_results.to_csv(csv_results_path, index=False)
            
            # Export CSV fitur (SEPERTI TABEL 3.3 DI LAPORAN)
            df_features = pd.DataFrame(batch_result['features'])
            csv_features_path = f"exports/{batch_name}_{split_ratio}_hasil_ekstraksi_fitur.csv"
            df_features.to_csv(csv_features_path, index=False)
            
            all_results.append({
                'split_ratio': split_ratio,
                'metrics': batch_result['metrics'],
                'confusion_matrix': batch_result['confusion_matrix'],
                'csv_results': csv_results_path,
                'csv_features': csv_features_path,
                'accuracy': batch_result['metrics']['accuracy'],
                'precision': batch_result['metrics']['precision'],
                'recall': batch_result['metrics']['recall'],
                'f1_score': batch_result['metrics']['f1_score'],
                'sensitivity': batch_result['metrics']['sensitivity'],
                'specificity': batch_result['metrics']['specificity']
            })
            
            print(f"‚úÖ {split_ratio} completed - Accuracy: {batch_result['metrics']['accuracy']}%")
        
        # Buat grafik perbandingan (SEPERTI GRAFIK DI LAPORAN)
        chart_path = create_comparison_chart(all_results)
        print(f"üìä Chart created: {chart_path}")
        
        return jsonify({
            'success': True,
            'batch_name': batch_name,
            'total_images': len(images_data),
            'results': all_results,
            'chart_path': chart_path
        })
        
    except Exception as e:
        print(f"Batch error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/export_csv/<filename>')
def export_csv(filename):
    """Download CSV"""
    try:
        filepath = f"exports/{filename}"
        return send_file(filepath, as_attachment=True)
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 404


@app.route('/export_chart/<filename>')
def export_chart(filename):
    """Download grafik"""
    try:
        filepath = f"charts/{filename}"
        return send_file(filepath, as_attachment=True, mimetype='image/png')
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 404


@app.route('/history')
def history():
    try:
        conn = sqlite3.connect('database/faces.db')
        c = conn.cursor()
        c.execute('SELECT * FROM detections ORDER BY id DESC LIMIT 50')
        rows = c.fetchall()
        conn.close()
        
        history_data = []
        for row in rows:
            history_data.append({
                'id': int(row[0]),
                'timestamp': str(row[1]),
                'face_count': int(row[2]),
                'eye_count': int(row[3]),
                'smile_count': int(row[4]),
                'process_time': int(row[5]),
                'image_path': str(row[6])
            })
        
        return jsonify(history_data)
    except Exception as e:
        return jsonify([])


@app.route('/batch_history')
def batch_history():
    """Riwayat batch testing"""
    try:
        conn = sqlite3.connect('database/faces.db')
        c = conn.cursor()
        c.execute('SELECT * FROM batch_results ORDER BY id DESC LIMIT 50')
        rows = c.fetchall()
        conn.close()
        
        batch_data = []
        for row in rows:
            batch_data.append({
                'id': int(row[0]),
                'batch_name': str(row[1]),
                'timestamp': str(row[2]),
                'split_ratio': str(row[3]),
                'total_images': int(row[4]),
                'tp': int(row[5]),
                'fp': int(row[6]),
                'tn': int(row[7]),
                'fn': int(row[8]),
                'accuracy': float(row[9]),
                'precision': float(row[10]),
                'recall': float(row[11]),
                'f1_score': float(row[12])
            })
        
        return jsonify(batch_data)
    except Exception as e:
        return jsonify([])


@app.route('/stats')
def stats():
    try:
        conn = sqlite3.connect('database/faces.db')
        c = conn.cursor()
        
        c.execute('SELECT COUNT(*), SUM(face_count), AVG(process_time) FROM detections')
        row = c.fetchone()
        
        conn.close()
        
        return jsonify({
            'total_detections': int(row[0] or 0),
            'total_faces': int(row[1] or 0),
            'avg_process_time': round(float(row[2] or 0), 2)
        })
    except Exception as e:
        return jsonify({'total_detections': 0, 'total_faces': 0, 'avg_process_time': 0})


# ============================================================
# MAIN
# ============================================================
if __name__ == '__main__':
    print("\n" + "="*70)
    print("   üöÄ SISTEM PENGENALAN POLA - DETEKSI WAJAH (100 DATA)")
    print("="*70)
    print("   üìç URL       : http://localhost:5000")
    print("   üìä Minimum   : 100 gambar untuk batch testing")
    print("   üî¨ Features  : 12 fitur (Integral, Histogram, Edge, Texture, Intensity)")
    print("   üìà Testing   : 3 Skenario (70:30, 80:20, 90:10)")
    print("   üéØ Metrics   : Accuracy, Precision, Recall, F1, Sensitivity, Specificity")
    print("   üìÅ Export    : CSV (Hasil Klasifikasi + Fitur) + Grafik PNG")
    print("="*70)
    print("\n   ‚è≥ Server running... (Ctrl+C untuk stop)\n")
    
    app.run(debug=True, host='0.0.0.0', port=5000)